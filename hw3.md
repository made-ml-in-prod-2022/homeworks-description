Суть этого ДЗ -- познакомиться с `airflow`.

Легенда:
1) Откуда-то берутся данные... Мы их используем для обучения МЛ модельки для задачи классификации.
2) Еженедельно, мы переобучаем модель на новых данных, ручками смотрим на метрики и если класс, то выкатываем ее на прод.
3) Ежедневно, текущая выбранная нами модель скорит данные и записывает предсказания куда-то.
4) Эти предсказания используют -- все счастливы =)

В ДЗ предлагается на основе `airflow` реализовать описанную выше схему, к деталям:

**Основная часть:**

0) Поднимите airflow локально, используя `docker compose` (можно использовать из примера https://github.com/made-ml-in-prod-2021/airflow-examples/)
1) Реализуйте dag, который генерирует данные для обучения модели (генерируйте данные -- можете использовать как генератор синтетики из первой дз, так и что-то из датасетов sklearn). Вам важно проэмулировать ситуации постоянно поступающих данных (5 баллов)

    - записывайте данные в `/data/raw/{{ ds }}/data.csv` и `/data/raw/{{ ds }}/target.csv`

2) Реализуйте dag, который обучает модель еженедельно, используя данные за текущий день. В вашем пайплайне должно быть как минимум 4 стадии, но дайте волю своей фантазии =) (10 баллов)

    - подготовить данные для обучения (например, считать из `/data/raw/{{ ds }}` и положить `/data/processed/{{ ds }}/train_data.csv`)
    - расплитить их на train/val
    - обучить модель на train, сохранить в `/data/models/{{ ds }}`
    - провалидировать модель на val (сохранить метрики к модельке)

3) Реализуйте dag, который использует модель ежедневно (5 баллов)
    - принимает на вход данные из пункта 1 (`data.csv`)
    - считывает путь до модельки из airflow variables (идея в том, что когда нам нравится другая модель и мы хотим ее на прод)
    - делает предсказание и записывает их в `/data/predictions/{{ ds }}/predictions.csv`

4) Вы можете выбрать 2 пути для выполнения ДЗ:
    - поставить все необходимые пакеты в образ с `airflow` и использовать `BashOperator`, `PythonOperator` (1 балл)
    - использовать `DockerOperator` -- тогда выполнение каждой из тасок должно запускаться в собственном контейнере  
      * один из дагов реализован с помощью `DockerOperator` (5 баллов)
      * все даги реализованы только с помощью `DockerOperator` (пример https://github.com/made-ml-in-prod-2021/airflow-examples/blob/main/dags/11_docker.py). По технике, вы можете использовать такую же структуру как в примере, пакуя в разные докеры скрипты, можете использовать общий докер с вашим пакетом, но с разными точками входа для разных тасок. Прикольно, если вы покажете, что для разных тасок можно использовать разный набор зависимостей (10 баллов)

      https://github.com/made-ml-in-prod-2021/airflow-examples/blob/main/dags/11_docker.py#L27 в этом месте пробрасывается путь с хостовой машины, используйте здесь путь типа `/tmp` или считывайте из переменных окружения.

5) Традиционно, самооценка (1 балл)

**Дополнительная часть**:

6) Реализуйте сенсоры на то, что данные готовы для дагов тренировки и обучения (+3 доп балла)
7) Протестируйте ваши даги https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html (+5 доп баллов) 
8) В `docker compose` так же настройте поднятие `mlflow` и запишите туда параметры обучения, метрики и артефакт (модель) (+5 доп баллов)
9) Вместо пути в airflow variables используйте API Mlflow Model Registry. Даг для инференса должен подхватывать последнюю продакшен модель (+5 доп баллов)
10) Настройте alert в случае падения дага https://www.astronomer.io/guides/error-notifications-in-airflow (+3 доп балла)

Чтобы получить баллы, сделайте скриншоты списка всех дагов и каждого графа по отдельности (в исполненном без ошибок виде) и прикрепите их в описание пулл реквеста.

**Процедура сдачи**:

Весь код должен находиться в том же репозитории, но в отдельной папке _airflow_ml_dags_. 

После выполнения ДЗ создаем пулл реквест, в ревьюеры добавляем  Mikhail-M, ждем комментариев (на которые нужно ответить) и/или оценки.
Ветка должна называться _homework3_.

Пожалуйста добавьте к своему пулл реквесту метку _hw3_. Если вы студент MADE, то дополнительно укажите тэг -- _MADE_, если вы студент Технопарка -- тэг _TECHNOPARK_.

**Сроки выполнения**:

Мягкий дедлайн: **20 июня 23:59**

Жесткий дедлайн:  **27 июня 23:59**

**Важно:** после мягкого дедлайна все полученные баллы умножаются на 0.6
